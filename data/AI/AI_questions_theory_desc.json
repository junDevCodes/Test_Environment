[
    {
        "subject": "[이론] Machine Learning",
        "question_text": "지도 학습, 비지도 학습, 강화 학습의 차이점을 각각의 목표, 사용 데이터, 대표적인 알고리즘 예시를 들어 비교 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "지도 학습은 정답이 있는 데이터를 사용하여 모델을 학습시켜 예측이나 분류를 수행하는 것이 목표입니다(예: 선형 회귀, 로지스틱 회귀). 비지도 학습은 정답 없는 데이터에서 숨겨진 구조나 패턴을 찾는 것이 목표입니다(예: K-평균 군집화, PCA). 강화 학습은 에이전트가 환경과 상호작용하며 보상을 최대화하는 행동을 학습하는 것이 목표입니다(예: Q-러닝).",
        "keywords_full_credit": ["지도 학습", "비지도 학습", "강화 학습", "정답 데이터 유무", "보상"],
        "keywords_partial_credit": ["예측/분류", "군집/패턴", "에이전트/환경", "선형 회귀", "K-평균", "Q-러닝"]
    },
    {
        "subject": "[이론] Machine Learning",
        "question_text": "로지스틱 회귀가 이진 분류 문제에 사용될 때, 선형 회귀의 예측 결과가 어떻게 시그모이드 함수를 통해 확률로 변환되는지 설명하고, 이진 교차 엔트로피 손실 함수가 왜 사용되는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "선형 회귀의 예측값(음의 무한대에서 양의 무한대)을 시그모이드 함수에 통과시키면 출력이 0과 1 사이의 값으로 변환되어 특정 클래스에 속할 확률로 해석할 수 있습니다. 이진 교차 엔트로피는 모델이 예측한 확률과 실제 정답(0 또는 1) 간의 차이를 측정하는 손실 함수로, 모델이 틀린 예측에 대해 높은 확신을 가질수록 더 큰 페널티를 부여하여 학습을 효과적으로 유도하기 때문에 사용됩니다.",
        "keywords_full_credit": ["시그모이드 함수", "0과 1 사이 확률", "이진 교차 엔트로피"],
        "keywords_partial_credit": ["선형 회귀", "이진 분류", "손실 함수", "페널티"]
    },
    {
        "subject": "[이론] EDA",
        "question_text": "박스 플롯(Box Plot)을 구성하는 5가지 주요 요소(최솟값, 1사분위수, 중앙값, 3사분위수, 최댓값)에 대해 설명하고, IQR(사분위수 범위)을 사용하여 이상치(outlier)를 정의하는 방법을 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "박스 플롯은 데이터의 분포를 시각화하는 도구입니다. 중앙값(50%)을 기준으로 데이터의 중간 지점을 나타내고, 1사분위수(25%)와 3사분위수(75%)는 각각 데이터의 하위 25%와 상위 25% 지점을 나타냅니다. 최솟값과 최댓값은 일반적으로 IQR(3사분위수 - 1사분위수)의 1.5배를 벗어나지 않는 범위 내의 데이터 포인트를 의미하며, 이 범위를 벗어나는 데이터 포인트를 이상치로 정의합니다.",
        "keywords_full_credit": ["중앙값", "1사분위수", "3사분위수", "IQR", "이상치"],
        "keywords_partial_credit": ["최솟값", "최댓값", "IQR의 1.5배"]
    },
    {
        "subject": "[이론] Model Evaluation",
        "question_text": "정밀도(Precision)와 재현율(Recall)은 상충 관계(Trade-off)에 있는 경우가 많습니다. 이 관계에 대해 설명하고, 스팸 메일 필터와 암 진단 모델 중 각각 어떤 지표가 더 중요하게 고려되어야 하는지 그 이유를 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "정밀도와 재현율은 상충 관계에 있습니다. 예를 들어, 모델이 Positive라고 예측하는 기준을 높이면(더 확실할 때만 Positive로 예측), 정밀도는 올라가지만 실제 Positive를 놓칠 가능성이 커져 재현율은 떨어집니다. 스팸 메일 필터에서는 정밀도가 더 중요합니다. 정상 메일을 스팸으로 잘못 분류(FP)하면 사용자가 중요한 정보를 놓칠 수 있기 때문입니다. 반면, 암 진단 모델에서는 재현율이 더 중요합니다. 실제 암 환자를 놓치는 것(FN)이 암이 아닌데 암으로 잘못 진단하는 것보다 훨씬 치명적이기 때문입니다.",
        "keywords_full_credit": ["상충 관계(Trade-off)", "정밀도", "재현율", "FN(False Negative)", "FP(False Positive)"],
        "keywords_partial_credit": ["스팸 메일", "암 진단", "분류 기준"]
    },
    {
        "subject": "[이론] Model Learning",
        "question_text": "모델의 과적합(Overfitting)과 과소적합(Underfitting)의 개념을 설명하고, 각각의 현상이 발생했을 때 훈련 데이터와 테스트 데이터에 대한 손실(loss) 또는 성능이 어떻게 나타나는지 특징을 비교하여 서술하시오.",
        "question_type": "descriptive",
        "model_answer": "과적합은 모델이 훈련 데이터에 너무 복잡하게 적응하여 노이즈까지 학습한 상태로, 훈련 데이터에서는 성능이 매우 높지만 새로운 테스트 데이터에서는 성능이 낮게 나타납니다. 과소적합은 모델이 너무 단순하여 훈련 데이터의 핵심 패턴조차 제대로 학습하지 못한 상태로, 훈련 데이터와 테스트 데이터 모두에서 성능이 낮게 나타납니다.",
        "keywords_full_credit": ["과적합", "과소적합", "훈련 데이터 성능", "테스트 데이터 성능"],
        "keywords_partial_credit": ["모델 복잡도", "노이즈 학습", "핵심 패턴"]
    },
    {
        "subject": "[이론] Optimization",
        "question_text": "경사 하강법에서 배치(Batch), 확률적(Stochastic), 미니배치(Mini-batch) 경사 하강법의 차이점을 학습 데이터 사용 방식과 가중치 업데이트 주관점에서 비교 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "배치 경사 하강법은 전체 훈련 데이터를 한 번에 사용하여 그래디언트를 계산하고 가중치를 한 번 업데이트합니다. 안정적이지만 계산 비용이 큽니다. 확률적 경사 하강법은 데이터 1개마다 그래디언트를 계산하고 가중치를 업데이트하여 매우 빠르지만, 학습 과정이 불안정할 수 있습니다. 미니배치 경사 하강법은 두 방식의 절충안으로, 데이터를 작은 묶음(미니배치)으로 나누어 각 미니배치마다 가중치를 업데이트하여 속도와 안정성의 균형을 맞춥니다.",
        "keywords_full_credit": ["배치 경사 하강법", "확률적 경사 하강법", "미니배치 경사 하강법", "데이터 사용 방식", "업데이트 주기"],
        "keywords_partial_credit": ["안정성", "계산 비용", "속도"]
    },
    {
        "subject": "[이론] Data Preprocessing",
        "question_text": "데이터 스케일링 기법인 표준화(Standardization)와 정규화(Normalization)의 목적과 계산 방식을 설명하고, 어떤 경우에 각각의 기법을 사용하는 것이 더 적절한지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "표준화는 데이터의 평균을 0, 표준편차를 1로 변환하는 기법으로, 이상치에 덜 민감하며 데이터가 정규분포를 따를 때 효과적입니다. 정규화는 데이터의 최솟값과 최댓값을 사용하여 모든 데이터를 0과 1 사이의 값으로 변환하는 기법으로, 데이터의 분포를 유지하면서 스케일을 맞추고 싶을 때 사용되지만 이상치에 민감합니다. 따라서 이상치가 많지 않고 데이터의 범위를 명확하게 제한하고 싶을 때 정규화를, 이상치가 존재하거나 데이터가 정규분포에 가까울 때 표준화를 사용하는 것이 일반적입니다.",
        "keywords_full_credit": ["표준화", "정규화", "평균 0 표준편차 1", "0과 1 사이"],
        "keywords_partial_credit": ["이상치 민감도", "데이터 분포"]
    },
    {
        "subject": "[이론] Deep Learning",
        "question_text": "딥러닝 모델에서 L1 규제와 L2 규제가 과적합을 방지하는 원리를 설명하고, 특히 L1 규제가 '특성 선택(feature selection)' 효과를 가지는 이유에 대해 서술하시오.",
        "question_type": "descriptive",
        "model_answer": "L1과 L2 규제는 손실 함수에 가중치의 크기에 대한 페널티 항을 추가하여 모델의 복잡도를 제한함으로써 과적합을 방지합니다. L2 규제는 가중치 제곱의 합을 페널티로 사용하여 가중치를 전반적으로 작게 만드는 효과가 있습니다. 반면, L1 규제는 가중치 절대값의 합을 페널티로 사용하는데, 이 방식은 최적화 과정에서 덜 중요한 특성의 가중치를 완전히 0으로 만드는 경향이 있습니다. 이 때문에 L1 규제는 모델 학습과 동시에 불필요한 특성을 제거하는 '특성 선택' 효과를 가집니다.",
        "keywords_full_credit": ["L1 규제", "L2 규제", "과적합 방지", "특성 선택"],
        "keywords_partial_credit": ["손실 함수", "페널티", "가중치 0"]
    },
    {
        "subject": "[이론] Deep Learning",
        "question_text": "심층 신경망(DNN)에서 '기울기 소실 문제(Vanishing Gradient Problem)'가 발생하는 원인과, 이 문제를 완화하기 위해 ReLU 활성화 함수가 어떻게 기여하는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "기울기 소실 문제는 역전파 과정에서 시그모이드나 하이퍼볼릭 탄젠트와 같은 활성화 함수의 미분값이 1보다 작은 구간이 많아, 층을 거슬러 올라갈수록 그래디언트가 점차 작아져 결국 0에 가까워지는 현상입니다. 이로 인해 앞쪽 층의 가중치가 거의 업데이트되지 않아 학습이 어려워집니다. ReLU 함수는 입력이 0보다 클 때 미분값이 항상 1이므로, 그래디언트가 소실되지 않고 앞쪽 층까지 잘 전달될 수 있도록 하여 이 문제를 완화하는 데 기여합니다.",
        "keywords_full_credit": ["기울기 소실", "역전파", "ReLU", "미분값 1"],
        "keywords_partial_credit": ["시그모이드", "가중치 업데이트"]
    },
    {
        "subject": "[이론] Deep Learning",
        "question_text": "Adam 옵티마이저가 '관성(Momentum)'과 '적응적 학습률(Adaptive Learning Rate)' 개념을 어떻게 결합하여 효율적인 학습을 가능하게 하는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "Adam 옵티마이저는 '관성' 개념을 사용하여 이전 그래디언트의 방향을 유지함으로써 학습의 진행 방향을 부드럽게 하고 지역 최적점을 더 잘 벗어날 수 있도록 합니다. 동시에, '적응적 학습률' 개념을 통해 각 파라미터마다 개별적인 학습률을 조절합니다. 즉, 자주 업데이트된 파라미터는 학습률을 줄이고, 드물게 업데이트된 파라미터는 학습률을 높여, 전체적으로 더 빠르고 안정적인 수렴을 가능하게 합니다.",
        "keywords_full_credit": ["Adam", "관성(Momentum)", "적응적 학습률"],
        "keywords_partial_credit": ["지역 최적점", "파라미터별 학습률 조절"]
    },
    {
        "subject": "[이론] NLP",
        "question_text": "Word2Vec의 CBOW와 Skip-gram 모델의 학습 방식을 비교 설명하고, 각각 어떤 경우에 더 유리한지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "CBOW(Continuous Bag-of-Words)는 주변 단어들을 통해 중심 단어를 예측하는 방식으로 학습하며, 학습 속도가 빠르고 자주 등장하는 단어의 표현에 유리합니다. Skip-gram은 중심 단어를 통해 주변 단어들을 예측하는 방식으로, 학습 속도는 느리지만 적은 양의 데이터에서도 잘 동작하며 특히 희귀 단어의 의미를 표현하는 데 더 유리합니다.",
        "keywords_full_credit": ["CBOW", "Skip-gram", "주변 단어 예측", "중심 단어 예측"],
        "keywords_partial_credit": ["학습 속도", "희귀 단어"]
    },
    {
        "subject": "[이론] NLP",
        "question_text": "Seq2Seq 모델에서 입력 시퀀스의 모든 정보를 고정된 크기의 벡터로 압축할 때 발생하는 '정보 병목 현상(Information Bottleneck)'에 대해 설명하고, 어텐션 메커니즘이 이 문제를 어떻게 해결하는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "정보 병목 현상은 인코더가 입력 시퀀스의 모든 정보를 하나의 고정된 크기 벡터(문맥 벡터)에 압축해야 하기 때문에, 시퀀스가 길어질수록 정보가 손실되는 문제입니다. 어텐션 메커니즘은 디코더가 각 타임스텝에서 출력을 생성할 때, 문맥 벡터 하나에만 의존하는 것이 아니라 인코더의 모든 타임스텝의 은닉 상태를 참고하여 현재 출력과 가장 관련이 높은 입력 부분에 더 집중(가중치를 부여)할 수 있도록 함으로써 이 문제를 해결합니다.",
        "keywords_full_credit": ["정보 병목 현상", "고정 크기 벡터", "어텐션 메커니즘", "입력 전체 참고"],
        "keywords_partial_credit": ["Seq2Seq", "인코더", "디코더"]
    },
    {
        "subject": "[이론] NLP",
        "question_text": "트랜스포머(Transformer) 모델의 셀프 어텐션(Self-Attention)에서 Query, Key, Value 벡터의 역할은 무엇이며, 이 세 가지 벡터를 사용하여 특정 단어의 문맥적 표현을 어떻게 계산하는지 그 과정을 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "셀프 어텐션에서 각 단어는 Query, Key, Value라는 세 가지 벡터로 표현됩니다. Query는 다른 단어들과의 관련성을 질문하는 역할을, Key는 각 단어가 가진 고유한 특성을 나타내는 역할을, Value는 단어의 실제 의미 정보를 담는 역할을 합니다. 특정 단어의 Query 벡터는 다른 모든 단어의 Key 벡터와 내적(dot product)되어 어텐션 스코어를 계산하고, 이 스코어에 소프트맥스를 취해 가중치를 구합니다. 마지막으로 이 가중치를 각 단어의 Value 벡터에 곱하여 가중합을 구함으로써, 문맥을 고려한 새로운 표현을 얻게 됩니다.",
        "keywords_full_credit": ["Query", "Key", "Value", "어텐션 스코어", "가중합"],
        "keywords_partial_credit": ["셀프 어텐션", "소프트맥스", "문맥적 표현"]
    },
    {
        "subject": "[이론] NLP",
        "question_text": "BERT 모델의 사전 학습 방법인 '마스크된 언어 모델(MLM)'과 '다음 문장 예측(NSP)'에 대해 각각 설명하고, 이 두 가지 방법이 모델의 양방향 문맥 이해 능력에 어떻게 기여하는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "MLM은 문장의 일부 단어를 [MASK] 토큰으로 가리고, 주변 단어들을 모두 참고하여 원래 단어를 예측하도록 학습하는 방식입니다. 이를 통해 모델은 단어의 왼쪽과 오른쪽 문맥을 동시에 이해하는 양방향 문맥 이해 능력을 기릅니다. NSP는 두 문장이 실제로 이어지는 문장인지를 예측하도록 학습하는 방식으로, 문장 간의 관계를 이해하는 능력을 모델에 부여합니다.",
        "keywords_full_credit": ["MLM", "NSP", "양방향 문맥", "문장 간 관계"],
        "keywords_partial_credit": ["BERT", "사전 학습", "[MASK]"]
    },
    {
        "subject": "[이론] CV",
        "question_text": "CNN(합성곱 신경망)의 '수용 영역(Receptive Field)' 개념에 대해 설명하고, 네트워크가 깊어질수록 수용 영역의 크기가 어떻게 변하며 이것이 이미지 특징 추출에 어떤 의미를 갖는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "수용 영역은 출력 특징 맵의 한 뉴런에 영향을 미치는 입력 이미지의 영역 크기를 의미합니다. CNN의 층이 깊어질수록(합성곱이나 풀링 층을 여러 번 통과할수록) 수용 영역은 점차 넓어집니다. 이는 모델이 초기 층에서는 엣지나 질감과 같은 지역적이고 단순한 특징을 학습하고, 깊은 층으로 갈수록 더 넓은 영역의 정보를 종합하여 객체의 부분이나 전체와 같은 더 복잡하고 추상적인 특징을 학습할 수 있게 됨을 의미합니다.",
        "keywords_full_credit": ["수용 영역", "층 깊이", "넓어짐", "복잡한 특징 학습"],
        "keywords_partial_credit": ["CNN", "지역적 특징", "추상적 특징"]
    },
    {
        "subject": "[이론] CV",
        "question_text": "ResNet(Residual Network)의 핵심 아이디어인 '잔차 연결(Residual Connection)' 또는 '스킵 연결(Skip Connection)'이 어떻게 깊은 신경망의 기울기 소실 문제를 완화하고 학습을 가능하게 하는지 그 원리를 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "잔차 연결은 특정 층의 입력(x)을 몇 개의 층을 건너뛴 후의 출력(F(x))에 그대로 더해주는(F(x) + x) 구조입니다. 역전파 시, 그래디언트가 이 스킵 연결을 통해 직접적으로 앞쪽 층으로 전달될 수 있는 '지름길' 역할을 합니다. 이로 인해 층이 매우 깊어져도 그래디언트가 소실되지 않고 효과적으로 전달되어, 깊은 신경망의 학습을 안정적으로 만듭니다.",
        "keywords_full_credit": ["잔차 연결", "스킵 연결", "기울기 소실 완화", "지름길"],
        "keywords_partial_credit": ["ResNet", "역전파", "F(x) + x"]
    },
    {
        "subject": "[이론] CV",
        "question_text": "Vision Transformer(ViT)가 이미지를 처리하는 과정을 단계별로 설명하시오. 특히, 이미지를 어떻게 시퀀스 데이터로 변환하며, 위치 정보를 어떻게 보존하는지에 초점을 맞춰 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "ViT는 이미지를 다음과 같이 처리합니다. 1) 이미지를 바둑판처럼 일정한 크기의 여러 패치(patch)로 나눕니다. 2) 각 패치를 선형 투영(linear projection)하여 고정된 크기의 벡터로 만듭니다. 3) 이 패치 벡터 시퀀스에 각 패치의 원래 위치 정보를 알려주기 위한 '위치 임베딩(Positional Embedding)'을 더해줍니다. 4) 이렇게 만들어진 벡터 시퀀스를 트랜스포머 인코더에 입력하여 이미지 전체의 문맥을 학습하고 최종적으로 분류를 수행합니다.",
        "keywords_full_credit": ["이미지 패치", "선형 투영", "위치 임베딩", "트랜스포머 인코더"],
        "keywords_partial_credit": ["ViT", "시퀀스 데이터 변환"]
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM(거대 언어 모델)의 '창발적 능력(Emergent Abilities)'이란 무엇이며, '인컨텍스트 학습(In-Context Learning)'이 어떻게 이 능력의 대표적인 예시가 되는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "창발적 능력은 모델의 크기(파라미터 수, 데이터 양 등)가 특정 임계점을 넘어서면서, 작은 모델에서는 나타나지 않았던 새로운 능력이 갑자기 나타나는 현상을 말합니다. '인컨텍스트 학습'은 이러한 창발적 능력의 대표적인 예시로, 모델에게 별도의 가중치 업데이트(학습) 없이 프롬프트에 몇 가지 예시(few-shot)를 제공하는 것만으로 새로운 작업을 수행하는 능력을 보여줍니다. 이는 작은 모델에서는 불가능했던 능력입니다.",
        "keywords_full_credit": ["창발적 능력", "인컨텍스트 학습", "모델 규모", "예시 기반 학습"],
        "keywords_partial_credit": ["LLM", "few-shot"]
    },
    {
        "subject": "[이론] LLM",
        "question_text": "RLHF(인간 피드백을 통한 강화학습)의 3단계 학습 과정을 순서대로 설명하고, 각 단계의 목표가 무엇인지 서술하시오.",
        "question_type": "descriptive",
        "model_answer": "RLHF는 3단계로 진행됩니다. 1단계는 '지도 미세조정(Supervised Fine-Tuning)'으로, 사람이 작성한 고품질의 지시-응답 데이터셋으로 사전 학습된 언어 모델을 추가 학습시켜 기본적인 지시 수행 능력을 갖추게 하는 것이 목표입니다. 2단계는 '보상 모델 학습'으로, 동일한 프롬프트에 대한 여러 응답에 대해 사람이 선호도 순위를 매긴 데이터를 사용하여, 특정 응답이 얼마나 좋은지를 평가하는 보상 모델을 학습시키는 것이 목표입니다. 3단계는 '강화학습을 통한 미세 조정'으로, 2단계에서 학습한 보상 모델을 보상 함수로 사용하여, 언어 모델(정책)이 더 높은 보상을 받는 응답을 생성하도록 강화학습(주로 PPO 알고리즘)을 통해 미세 조정하는 것이 목표입니다.",
        "keywords_full_credit": ["지도 미세조정", "보상 모델 학습", "강화학습을 통한 미세 조정"],
        "keywords_partial_credit": ["RLHF", "선호도 데이터", "PPO"]
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM의 환각(Hallucination) 현상을 완화하기 위한 RAG(검색 증강 생성)의 기본 원리를 설명하고, RAG 시스템의 주요 구성 요소(Retriever, Generator)가 어떻게 상호작용하여 신뢰성 있는 답변을 생성하는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "RAG는 LLM이 답변을 생성할 때, 모델 내부의 지식에만 의존하는 것이 아니라 외부의 신뢰할 수 있는 지식 소스(예: 데이터베이스, 문서)에서 관련 정보를 실시간으로 검색하여 이를 근거로 답변을 생성하는 방식입니다. 사용자의 질문이 들어오면 Retriever가 지식 소스에서 가장 관련성 높은 정보를 검색하고, Generator(LLM)는 이 검색된 정보와 원래 질문을 함께 입력받아, 사실에 기반한 더 정확하고 신뢰성 있는 답변을 생성합니다. 이를 통해 LLM이 잘못되거나 지어낸 정보를 생성하는 환각 현상을 크게 줄일 수 있습니다.",
        "keywords_full_credit": ["RAG", "환각 완화", "외부 지식 소스", "검색(Retrieval)", "생성(Generation)"],
        "keywords_partial_credit": ["Retriever", "Generator", "사실 기반"]
    },
    {
        "subject": "[이론] PEFT",
        "question_text": "PEFT(Parameter-Efficient Fine-Tuning) 기법 중 하나인 LoRA(Low-Rank Adaptation)가 어떻게 작동하는지 설명하고, `r` (rank)과 `lora_alpha` 하이퍼파라미터가 모델 학습에 어떤 영향을 미치는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "LoRA는 사전 학습된 모델의 가중치(W)는 고정한 채, 그 옆에 랭크가 낮은 두 개의 작은 행렬(A, B)을 추가하여 이 행렬들만 학습시키는 방식입니다. `r`은 이 행렬들의 랭크(차원)를 결정하며, 클수록 표현력은 높아지지만 학습 파라미터 수가 증가합니다. `lora_alpha`는 학습된 LoRA 가중치의 스케일링 값으로, 보통 `r`의 2배수로 설정하여 학습된 가중치의 영향력을 조절하는 역할을 합니다.",
        "keywords_full_credit": ["LoRA", "PEFT", "가중치 고정", "저랭크 행렬(A, B)", "r(rank)", "lora_alpha"],
        "keywords_partial_credit": ["스케일링", "파라미터 효율"]
    },
    {
        "subject": "[이론] PEFT",
        "question_text": "QLoRA는 LoRA와 어떻게 다르며, 4-bit 정밀도를 사용함에도 불구하고 어떻게 준수한 성능을 유지할 수 있는지 그 핵심 원리(e.g., NormalFloat, Double Quantization)에 대해 간략히 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "QLoRA는 사전 학습된 모델의 가중치를 4-bit의 낮은 정밀도로 양자화하여 메모리 사용량을 크게 줄인 상태에서 LoRA를 적용하는 기법입니다. NormalFloat(NF4)라는 새로운 데이터 타입을 사용하여 정보 손실을 최소화하고, 양자화 상수를 다시 양자화하는 Double Quantization을 통해 메모리를 추가로 절약하면서도 준수한 성능을 유지합니다.",
        "keywords_full_credit": ["QLoRA", "4-bit 양자화", "NormalFloat(NF4)", "Double Quantization"],
        "keywords_partial_credit": ["LoRA", "메모리 절약"]
    },
    {
        "subject": "[이론] Model Compression",
        "question_text": "모델 경량화 기법인 양자화(Quantization)와 가지치기(Pruning)의 차이점을 설명하고, 이 두 기법을 함께 사용했을 때 얻을 수 있는 시너지 효과에 대해 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "양자화는 모델의 가중치를 표현하는 비트 수를 줄여(예: 32-bit -> 8-bit) 모델 크기와 연산량을 줄이는 기술입니다. 가지치기는 모델의 가중치 중 중요도가 낮은 연결을 제거하여 모델을 더 희소(sparse)하게 만드는 기술입니다. 이 두 기법을 함께 사용하면, 가지치기를 통해 불필요한 파라미터를 제거하고, 남은 파라미터들을 양자화하여 모델을 더욱 압축하고 추론 속도를 향상시키는 시너지 효과를 얻을 수 있습니다.",
        "keywords_full_credit": ["양자화(Quantization)", "가지치기(Pruning)", "비트 수 감소", "가중치 제거"],
        "keywords_partial_credit": ["모델 경량화", "희소 행렬", "시너지 효과"]
    },
    {
        "subject": "[이론] Model Compression",
        "question_text": "지식 증류(Knowledge Distillation)에서 '교사 모델(Teacher Model)'과 '학생 모델(Student Model)'의 역할은 무엇이며, 학생 모델이 교사 모델의 '소프트 레이블(soft label)'을 학습하는 것이 어떤 이점을 가지는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "지식 증류에서 교사 모델은 크고 성능이 좋은 모델이며, 학생 모델은 작고 효율적인 모델입니다. 학생 모델은 교사 모델의 예측 결과를 학습하는데, 이때 교사 모델이 출력하는 클래스별 확률 분포 전체(소프트 레이블)를 학습하게 됩니다. 이는 정답 레이블(하드 레이블)만 학습하는 것보다 클래스 간의 미묘한 관계나 교사 모델의 '생각 과정'까지 배울 수 있게 하여, 학생 모델이 더 좋은 일반화 성능을 갖도록 돕습니다.",
        "keywords_full_credit": ["지식 증류", "교사 모델", "학생 모델", "소프트 레이블"],
        "keywords_partial_credit": ["일반화 성능", "클래스 확률 분포"]
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM의 디코딩 전략 중, Greedy Decoding과 Beam Search의 차이점을 설명하고, Beam Search가 어떻게 더 나은 품질의 문장을 생성할 수 있는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "Greedy Decoding은 각 타임스텝에서 가장 확률이 높은 단 하나의 토큰만을 선택하는 방식입니다. 반면, Beam Search는 각 타임스텝에서 확률이 높은 K개의 후보 시퀀스(beam)를 유지하고, 다음 단계에서 이 후보들을 확장하여 누적 확률이 가장 높은 시퀀스를 탐색합니다. 이를 통해 당장의 최적 선택이 아닌, 전체 문장의 관점에서 더 자연스럽고 품질이 높은 문장을 생성할 가능성을 높입니다.",
        "keywords_full_credit": ["Greedy Decoding", "Beam Search", "가장 확률 높은 토큰", "K개 후보 시퀀스"],
        "keywords_partial_credit": ["디코딩 전략", "누적 확률"]
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM의 답변 생성 다양성을 조절하는 Top-K 샘플링과 Top-P(Nucleus) 샘플링의 작동 방식을 비교 설명하고, 왜 Top-P 샘플링이 더 유연한 전략으로 평가받는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "Top-K 샘플링은 확률 분포에서 가장 확률이 높은 K개의 토큰 중에서만 다음 토큰을 샘플링하는 방식입니다. Top-P 샘플링은 누적 확률이 P가 될 때까지의 상위 토큰들(핵)을 후보로 하여 샘플링합니다. Top-P가 더 유연한 이유는 확률 분포의 모양에 따라 후보군의 크기를 동적으로 조절하기 때문입니다. 즉, 확률이 특정 토큰에 집중된 경우에는 후보군을 작게, 확률이 여러 토큰에 분산된 경우에는 후보군을 크게 만들어 문맥에 맞는 자연스러운 답변을 생성하는 데 더 유리합니다.",
        "keywords_full_credit": ["Top-K 샘플링", "Top-P 샘플링", "고정된 K개", "누적 확률 P"],
        "keywords_partial_credit": ["샘플링", "다양성 조절", "동적 조절"]
    },
    {
        "subject": "[이론] RAG",
        "question_text": "RAG 시스템에서 사용되는 Sparse Retriever(예: TF-IDF)와 Dense Retriever(예: Bi-encoder 기반)의 검색 원리 차이를 설명하고, 이 둘을 결합한 하이브리드 검색(Hybrid Search)이 왜 효과적인지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "Sparse Retriever는 TF-IDF와 같이 단어의 빈도와 희소성을 기반으로 한 키워드 매칭 방식으로 검색합니다. 반면, Dense Retriever는 문장의 의미를 벡터로 임베딩하여 의미적 유사도를 기반으로 검색합니다. 하이브리드 검색은 이 둘을 결합한 것으로, 키워드가 정확히 일치하는 경우에 강한 Sparse 검색과 문맥적 의미를 잘 파악하는 Dense 검색의 장점을 모두 활용하여 더 정확하고 관련성 높은 검색 결과를 얻을 수 있기 때문에 효과적입니다.",
        "keywords_full_credit": ["Sparse Retriever", "Dense Retriever", "키워드 기반", "의미 기반"],
        "keywords_partial_credit": ["TF-IDF", "임베딩", "하이브리드 검색"]
    },
    {
        "subject": "[이론] RAG",
        "question_text": "RAG 파이프라인에서 '청킹(Chunking)' 전략이 왜 중요한지 설명하고, `chunk_size`와 `chunk_overlap` 파라미터가 검색 성능에 어떤 영향을 미치는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "청킹은 긴 문서를 LLM의 컨텍스트 창에 맞게 의미 있는 작은 단위로 나누는 과정으로, 관련성 높은 정보를 정확하게 검색하고 LLM에 전달하기 위해 중요합니다. `chunk_size`는 청크의 크기를 결정하며, 너무 크면 관련 없는 정보가 포함되고 너무 작으면 문맥이 손실될 수 있습니다. `chunk_overlap`은 인접한 청크 간에 내용을 겹치게 하여, 문장의 의미가 청크 경계에서 잘리는 것을 방지하고 문맥의 연속성을 유지하는 역할을 합니다.",
        "keywords_full_credit": ["청킹(Chunking)", "컨텍스트 창", "chunk_size", "chunk_overlap"],
        "keywords_partial_credit": ["검색 성능", "문맥 손실 방지"]
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM의 'Jailbreaking'이란 무엇이며, 이것이 LLM의 '정렬(Alignment)' 학습과 어떤 관련이 있는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "Jailbreaking은 특수하게 조작된 프롬프트를 사용하여 LLM이 따르도록 설정된 안전 정책이나 윤리적 가이드라인을 우회하여, 유해하거나 부적절한 콘텐츠를 생성하도록 유도하는 행위를 말합니다. 이는 LLM을 유용하고 무해하게 만들려는 '정렬' 학습의 목표를 무력화시키려는 시도와 직접적으로 관련이 있으며, 정렬 기술의 견고성을 테스트하고 개선하는 데 중요한 연구 주제가 됩니다.",
        "keywords_full_credit": ["Jailbreaking", "안전 정책 우회", "정렬(Alignment)"],
        "keywords_partial_credit": ["유해한 콘텐츠", "프롬프트 조작"]
    },
    {
        "subject": "[이론] Model Evaluation",
        "question_text": "LLM의 성능을 평가하는 자동화된 방식인 'LLM-as-a-judge'의 개념을 설명하고, 이 방식이 가질 수 있는 잠재적인 편향(bias) 3가지(위치, 길이, 자기 선호)에 대해 각각 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "'LLM-as-a-judge'는 사람이 직접 평가하는 대신, 다른 강력한 LLM을 사용하여 모델의 응답 품질을 자동으로 평가하는 방식입니다. 이 방식은 위치 편향(먼저 제시된 답변을 선호), 길이 편향(품질과 상관없이 긴 답변을 선호), 자기 선호 편향(평가 모델이 자신이 생성했을 법한 스타일의 답변을 선호)과 같은 잠재적인 편향을 가질 수 있어 평가 결과의 신뢰성에 영향을 줄 수 있습니다.",
        "keywords_full_credit": ["LLM-as-a-judge", "위치 편향", "길이 편향", "자기 선호 편향"],
        "keywords_partial_credit": ["자동 평가", "신뢰성"]
    },
    {
        "subject": "[이론] Machine Learning",
        "question_text": "K-Fold 교차 검증(K-Fold Cross-Validation)의 절차를 설명하고, 이 기법이 모델의 일반화 성능을 평가하는 데 왜 신뢰성 있는 방법으로 간주되는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "K-Fold 교차 검증은 전체 훈련 데이터를 K개의 부분집합(fold)으로 나눈 뒤, K-1개를 훈련에 사용하고 나머지 1개를 검증에 사용하는 과정을 K번 반복합니다. 각 반복마다 검증 폴드를 다르게 하여 모든 데이터가 한 번씩 검증에 사용되도록 합니다. 이 방법은 데이터를 훈련용과 테스트용으로 한 번만 나누는 것에 비해, 모든 데이터가 평가에 기여하므로 특정 데이터 분할에 따른 편향을 줄이고 모델의 일반화 성능을 더 안정적이고 신뢰성 있게 추정할 수 있습니다.",
        "keywords_full_credit": ["K-Fold 교차 검증", "K개의 부분집합", "일반화 성능", "편향 감소"],
        "keywords_partial_credit": ["훈련/검증 반복", "신뢰성"]
    },
    {
        "subject": "[이론] NLP",
        "question_text": "트랜스포머(Transformer) 아키텍처가 RNN 기반 모델에 비해 갖는 주요 장점 두 가지를 설명하고, '위치 인코딩(Positional Encoding)'이 왜 트랜스포머에 필수적인지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "트랜스포머의 주요 장점은 1) 셀프 어텐션을 통해 시퀀스 내 단어들의 관계를 한 번에 병렬적으로 계산할 수 있어 학습 속도가 매우 빠르다는 것과 2) 층이 깊어져도 RNN의 장기 의존성 문제(기울기 소실 등)가 발생하지 않는다는 점입니다. '위치 인코딩'이 필수적인 이유는, 트랜스포머는 RNN과 달리 단어를 순차적으로 처리하지 않기 때문에 모델 자체적으로 단어의 순서 정보를 알 수 없기 때문입니다. 따라서 각 단어의 위치 정보를 담은 벡터를 입력 임베딩에 더해줌으로써 모델이 단어의 순서를 이해할 수 있도록 해야 합니다.",
        "keywords_full_credit": ["병렬 처리", "장기 의존성 문제 해결", "위치 인코딩", "순서 정보"],
        "keywords_partial_credit": ["트랜스포머", "RNN", "셀프 어텐션"]
    },
    {
        "subject": "[이론] Model Compression",
        "question_text": "모델 경량화 기법 중, 정형 가지치기(Structured Pruning)와 비정형 가지치기(Unstructured Pruning)의 차이점을 설명하고, 실제 하드웨어에서 추론 속도 향상을 위해서는 어떤 방식이 더 유리한지 그 이유를 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "비정형 가지치기는 모델의 개별 가중치를 중요도에 따라 제거하는 방식이고, 정형 가지치기는 필터나 채널과 같은 구조적인 단위를 통째로 제거하는 방식입니다. 실제 하드웨어에서 속도 향상을 위해서는 정형 가지치기가 더 유리합니다. 비정형 가지치기는 불규칙한 희소 행렬을 만들어 특수한 하드웨어나 라이브러리 없이는 연산 가속이 어렵지만, 정형 가지치기는 모델의 구조 자체를 더 작고 규칙적으로 만들어 일반적인 하드웨어에서도 쉽게 병렬 연산을 통한 속도 향상을 꾀할 수 있기 때문입니다.",
        "keywords_full_credit": ["정형 가지치기", "비정형 가지치기", "구조적 단위 제거", "추론 속도 향상"],
        "keywords_partial_credit": ["모델 경량화", "희소 행렬", "병렬 연산"]
    },
    {
        "subject": "[이론] LLM",
        "question_text": "'Chain-of-Thought (CoT)' 프롬프팅이 LLM의 복잡한 추론 능력을 어떻게 향상시키는지 설명하고, 'Zero-shot-CoT'가 기존의 CoT와 어떻게 다른지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "CoT는 LLM에게 문제에 대한 최종 답변만 요구하는 대신, 정답에 도달하기까지의 중간 추론 과정을 단계별로 생각하고 설명하도록 유도하는 프롬프팅 기법입니다. 이를 통해 복잡한 문제를 작은 단계로 나누어 해결하게 함으로써 추론의 정확성을 높입니다. 기존의 CoT는 프롬프트에 몇 가지 풀이 예시를 포함해야 하지만, 'Zero-shot-CoT'는 '단계별로 생각해보자(Let's think step by step)'와 같은 간단한 지시어만 추가하여 예시 없이도 LLM 스스로 추론 과정을 생성하도록 유도하는 방식입니다.",
        "keywords_full_credit": ["Chain-of-Thought", "추론 과정", "Zero-shot-CoT", "예시 없음"],
        "keywords_partial_credit": ["LLM", "추론 능력 향상", "단계별 해결"]
    },
    {
        "subject": "[이론] RAG",
        "question_text": "RAG 시스템에서 Bi-Encoder와 Cross-Encoder의 역할과 장단점을 비교 설명하고, 효율적인 검색을 위해 이 두 인코더를 어떻게 조합하여 2단계 검색(Two-stage Retrieval)을 구성할 수 있는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "Bi-Encoder는 질문과 문서를 각각 독립적으로 임베딩하여 유사도를 계산하므로 속도가 매우 빠르지만, 상호작용을 고려하지 않아 정확도가 상대적으로 낮습니다. Cross-Encoder는 질문과 문서를 쌍으로 입력받아 관련성을 직접 판단하므로 정확도가 높지만, 모든 문서와 쌍을 이루어야 하므로 매우 느립니다. 효율적인 2단계 검색은 1단계에서 Bi-Encoder를 사용하여 대규모 문서에서 빠르게 후보군을 추리고, 2단계에서 이 후보군에 대해서만 Cross-Encoder를 사용하여 정확하게 재순위(re-ranking)를 매겨 최종 결과를 얻는 방식으로 구성할 수 있습니다.",
        "keywords_full_credit": ["Bi-Encoder", "Cross-Encoder", "2단계 검색", "재순위(re-ranking)"],
        "keywords_partial_credit": ["속도", "정확도", "후보군"]
    },
    {
        "subject": "[이론] 종합",
        "question_text": "이미지 캡셔닝(Image Captioning) 작업을 수행하기 위한 딥러닝 모델을 설계한다고 가정할 때, CNN과 RNN(또는 트랜스포머)을 어떻게 조합하여 인코더-디코더 구조를 만들 수 있는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "이미지 캡셔닝 모델은 주로 CNN 인코더와 RNN/트랜스포머 디코더 구조로 설계됩니다. 먼저, 사전 학습된 CNN(예: ResNet)을 인코더로 사용하여 입력 이미지의 특징을 추출하고 이를 고정된 크기의 벡터로 만듭니다. 그 다음, RNN 또는 트랜스포머 기반의 디코더가 이 이미지 벡터를 초기 입력으로 받아, 이미지의 내용을 설명하는 캡션(문장)을 단어 단위로 순차적으로 생성합니다. 즉, CNN이 이미지의 '내용'을 이해하고, RNN/트랜스포머가 그 내용을 '문장'으로 번역하는 역할을 합니다.",
        "keywords_full_credit": ["CNN 인코더", "RNN/트랜스포머 디코더", "이미지 특징 추출", "캡션 생성"],
        "keywords_partial_credit": ["이미지 캡셔닝", "인코더-디코더"]
    },
    {
        "subject": "[이론] 종합",
        "question_text": "딥러닝 모델의 학습 과정에서 발생하는 '과적합(Overfitting)'을 완화하기 위한 규제(Regularization) 기법 3가지(예: L1/L2 규제, 드롭아웃, 조기 종료)를 들고 각각의 작동 원리를 간략히 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "1. **L1/L2 규제**: 손실 함수에 가중치의 크기에 대한 페널티를 추가하여, 모델의 가중치가 너무 커지지 않도록 제한합니다. 이를 통해 모델의 복잡도를 낮추고 일반화 성능을 향상시킵니다. 2. **드롭아웃(Dropout)**: 학습 과정에서 각 뉴런을 일정 확률로 무작위로 비활성화시킵니다. 이를 통해 모델이 특정 뉴런에 과도하게 의존하는 것을 방지하고, 여러 개의 작은 모델을 앙상블하는 것과 유사한 효과를 냅니다. 3. **조기 종료(Early Stopping)**: 검증 데이터에 대한 성능이 더 이상 개선되지 않고 과적합의 징후가 보일 때 학습을 조기에 중단하여, 최적의 일반화 성능을 가진 지점에서 모델 학습을 멈춥니다.",
        "keywords_full_credit": ["L1/L2 규제", "드롭아웃", "조기 종료", "과적합 완화"],
        "keywords_partial_credit": ["가중치 페널티", "뉴런 비활성화", "검증 데이터"]
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM의 '정렬(Alignment)' 학습의 목표는 무엇이며, 이를 달성하기 위한 주요 학습 단계인 '지시 학습(Instruction Tuning)'과 '선호 학습(Preference Learning, e.g., RLHF)'이 각각 어떤 역할을 하는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "정렬 학습의 목표는 LLM이 인간의 가치관과 의도에 부합하는, 즉 유용하면서도 무해한 답변을 생성하도록 만드는 것입니다. '지시 학습'은 다양한 지시(instruction)와 그에 대한 정답 응답 데이터셋을 통해 모델이 사람의 지시를 따르는 기본적인 능력을 학습시키는 역할을 합니다. '선호 학습(RLHF 등)'은 사람이 선호하는 응답에 더 높은 보상을 주도록 보상 모델을 학습시키고, 이 보상 모델을 이용한 강화학습을 통해 LLM이 더 자연스럽고 사람의 선호에 맞는 응답을 생성하도록 미세 조정하는 역할을 합니다.",
        "keywords_full_credit": ["정렬(Alignment)", "지시 학습", "선호 학습(RLHF)", "유용성/무해성"],
        "keywords_partial_credit": ["인간 가치관", "보상 모델"]
    },
    {
        "subject": "[이론] RAG",
        "question_text": "LangChain의 LCEL(LangChain Expression Language)을 사용하여 RAG 체인을 구성하는 과정을 설명하시오. `RunnablePassthrough`는 이 과정에서 어떤 유용한 역할을 할 수 있는지 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "LCEL을 사용한 RAG 체인은 보통 `retriever`, `prompt`, `model`, `output_parser`와 같은 컴포넌트들을 파이프(|) 연산자로 연결하여 구성합니다. 예를 들어, `retriever`가 검색한 문맥과 원래 질문을 프롬프트 템플릿에 전달하고, 완성된 프롬프트를 모델에 입력한 뒤, 모델의 출력을 파서로 정리하는 흐름을 만듭니다. 이때 `RunnablePassthrough`는 특정 단계의 입력을 수정 없이 그대로 다음 단계로 전달하는 역할을 합니다. 예를 들어, retriever의 입력으로 원래 질문을 그대로 사용하고 싶을 때 `{\"context\": retriever, \"question\": RunnablePassthrough()}`와 같이 사용하여 체인의 데이터 흐름을 유연하게 제어할 수 있습니다.",
        "keywords_full_credit": ["LCEL", "파이프 연산자(|)", "RunnablePassthrough", "체인 구성"],
        "keywords_partial_credit": ["retriever", "prompt", "model"]
    },
    {
        "subject": "[이론] 종합",
        "question_text": "딥러닝 모델의 파라미터 수를 줄여 경량화하는 대표적인 두 가지 방법인 '가지치기(Pruning)'와 '지식 증류(Knowledge Distillation)'의 기본 아이디어를 비교 설명하시오.",
        "question_type": "descriptive",
        "model_answer": "'가지치기'는 학습된 모델에서 중요도가 낮은 가중치나 뉴런, 필터 등을 물리적으로 제거하여 모델의 파라미터 수를 직접적으로 줄이는 방식입니다. 반면, '지식 증류'는 크고 성능이 좋은 교사 모델의 예측 결과(소프트 레이블)를 정답으로 사용하여, 작고 효율적인 학생 모델을 학습시키는 방식입니다. 즉, 가지치기는 기존 모델을 '다이어트'시키는 것이고, 지식 증류는 똑똑한 교사의 '노하우'를 작은 학생에게 전수하는 것에 비유할 수 있습니다.",
        "keywords_full_credit": ["가지치기(Pruning)", "지식 증류", "가중치 제거", "교사/학생 모델"],
        "keywords_partial_credit": ["모델 경량화", "소프트 레이블"]
    }
]