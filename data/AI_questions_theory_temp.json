[
    {
        "subject": "[이론] 머신러닝",
        "question_text": "K-Means 군집화에서 초기 중심점(centroid) 위치에 따라 결과가 달라질 수 있는 문제를 완화하기 위한 방법으로 가장 적절한 것은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["K값을 1로 설정한다", "데이터를 정규화한다", "여러 번 다른 초기 중심으로 실행하고 최상의 결과를 선택한다", "군집의 개수를 데이터 포인트의 개수와 동일하게 설정한다"],
        "model_answer": "여러 번 다른 초기 중심으로 실행하고 최상의 결과를 선택한다"
    },
    {
        "subject": "[이론] 머신러닝",
        "question_text": "계층적 군집(Hierarchical Clustering)에 대한 설명으로 가장 올바른 것은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["미리 군집의 개수(K)를 정해야 한다.", "데이터 포인트 간의 거리를 기반으로 가장 가까운 것부터 순차적으로 묶어나간다.", "모든 군집이 동일한 크기를 갖도록 보장한다.", "연속적인 값을 예측하는 데 사용된다."],
        "model_answer": "데이터 포인트 간의 거리를 기반으로 가장 가까운 것부터 순차적으로 묶어나간다."
    },
    {
        "subject": "[이론] 최적화",
        "question_text": "경사 하강법에서 학습률이 너무 클 때 발생할 수 있는 가장 대표적인 문제는 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["학습 속도가 매우 느려진다.", "최적점에 수렴하지 못하고 발산(overshooting)할 수 있다.", "지역 최적점(local minimum)에 빠지기 쉽다.", "모델의 과소적합을 유발한다."],
        "model_answer": "최적점에 수렴하지 못하고 발산(overshooting)할 수 있다."
    },
    {
        "subject": "[이론] EDA",
        "question_text": "데이터의 분포를 시각화할 때, 특정 구간에 데이터가 얼마나 집중되어 있는지 막대 그래프 형태로 보여주는 것은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["산점도(Scatter Plot)", "선 그래프(Line Plot)", "히스토그램(Histogram)", "파이 차트(Pie Chart)"],
        "model_answer": "히스토그램(Histogram)"
    },
    {
        "subject": "[이론] 모델 평가",
        "question_text": "분류 모델의 평가지표 중, (TP + TN) / (TP + TN + FP + FN) 수식으로 계산되는 것은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["정밀도(Precision)", "재현율(Recall)", "정확도(Accuracy)", "F1-Score"],
        "model_answer": "정확도(Accuracy)"
    },
    {
        "subject": "[이론] 딥러닝",
        "question_text": "딥러닝 모델의 학습 과정에서 손실(loss)이 더 이상 감소하지 않고 검증 데이터에 대한 성능이 저하되기 시작할 때 학습을 중단하는 기법은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["조기 종료(Early Stopping)", "경사 하강법(Gradient Descent)", "드롭아웃(Dropout)", "배치 정규화(Batch Normalization)"],
        "model_answer": "조기 종료(Early Stopping)"
    },
    {
        "subject": "[이론] 딥러닝",
        "question_text": "L1 규제(Lasso)가 L2 규제(Ridge)와 구별되는 가장 큰 특징은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["가중치를 0에 가깝게 만들지만 0으로 만들지는 않는다.", "일부 가중치를 완전히 0으로 만들어 특성 선택(feature selection) 효과를 가진다.", "모델의 복잡도에 영향을 주지 않는다.", "항상 L2 규제보다 더 나은 성능을 보인다."],
        "model_answer": "일부 가중치를 완전히 0으로 만들어 특성 선택(feature selection) 효과를 가진다."
    },
    {
        "subject": "[이론] 딥러닝",
        "question_text": "딥러닝에서, 신경망의 각 레이어를 통과한 데이터의 분포가 바뀌는 현상(Internal Covariate Shift)을 완화하여 학습을 안정시키는 기법은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["드롭아웃(Dropout)", "배치 정규화(Batch Normalization)", "가중치 초기화(Weight Initialization)", "활성화 함수(Activation Function)"],
        "model_answer": "배치 정규화(Batch Normalization)"
    },
    {
        "subject": "[이론] CV",
        "question_text": "CNN에서, 입력 데이터의 채널 수는 유지하면서 공간적 크기(가로, 세로)를 줄이는 데 사용되는 연산은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["1x1 합성곱", "패딩(Padding)", "풀링(Pooling)", "업샘플링(Upsampling)"],
        "model_answer": "풀링(Pooling)"
    },
    {
        "subject": "[이론] NLP",
        "question_text": "순차적 데이터의 맥락을 양방향으로 고려하기 위해 RNN을 변형한 모델은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["단방향 RNN (Unidirectional RNN)", "양방향 RNN (Bidirectional RNN)", "심층 RNN (Deep RNN)", "합성곱 RNN (Convolutional RNN)"],
        "model_answer": "양방향 RNN (Bidirectional RNN)"
    },
    {
        "subject": "[이론] NLP",
        "question_text": "LSTM의 셀 상태(Cell State)가 하는 역할로 가장 적절한 설명은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["현재 타임스텝의 입력만을 처리한다.", "시퀀스의 장기적인 정보를 컨베이어 벨트처럼 전달하여 장기 의존성 문제를 해결한다.", "모델의 최종 출력을 결정한다.", "인접한 단어 간의 관계만 학습한다."],
        "model_answer": "시퀀스의 장기적인 정보를 컨베이어 벨트처럼 전달하여 장기 의존성 문제를 해결한다."
    },
    {
        "subject": "[이론] NLP",
        "question_text": "트랜스포머의 멀티-헤드 어텐션(Multi-Head Attention)이 단일 어텐션에 비해 갖는 장점은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["계산 속도가 더 빠르다.", "더 적은 메모리를 사용한다.", "다양한 관점에서 단어 간의 관계를 동시에 학습할 수 있다.", "항상 더 짧은 문장을 생성한다."],
        "model_answer": "다양한 관점에서 단어 간의 관계를 동시에 학습할 수 있다."
    },
    {
        "subject": "[이론] NLP",
        "question_text": "BERT 모델의 사전 학습에서, 두 문장이 연속된 문장인지 아닌지를 예측하도록 학습하는 태스크는 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["MLM (Masked Language Model)", "NSP (Next Sentence Prediction)", "QA (Question Answering)", "NLI (Natural Language Inference)"],
        "model_answer": "NSP (Next Sentence Prediction)"
    },
    {
        "subject": "[이론] CV",
        "question_text": "CNN 아키텍처 중, 동일한 크기의 필터를 반복적으로 깊게 쌓는 단순한 구조를 통해 깊이의 중요성을 입증한 모델은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["AlexNet", "VGGNet", "GoogLeNet (Inception)", "ResNet"],
        "model_answer": "VGGNet"
    },
    {
        "subject": "[이론] CV",
        "question_text": "ViT(Vision Transformer)에서 입력 이미지를 패치로 나눈 후, 각 패치의 순서 정보를 모델에 제공하기 위해 더해지는 것은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["클래스 토큰 (Class Token)", "위치 임베딩 (Positional Embedding)", "세그먼트 ID (Segment ID)", "어텐션 스코어 (Attention Score)"],
        "model_answer": "위치 임베딩 (Positional Embedding)"
    },
    {
        "subject": "[이론] RAG",
        "question_text": "RAG 시스템에서, 검색된 문서(context)와 사용자 질문을 함께 LLM에 입력하여 답변을 생성하게 하는 주된 이유는 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["모델의 응답 속도를 높이기 위해", "모델이 사실에 기반하고 더 정확한 답변을 생성하도록 유도하기 위해", "모델의 창의성을 극대화하기 위해", "입력 텍스트의 길이를 줄이기 위해"],
        "model_answer": "모델이 사실에 기반하고 더 정확한 답변을 생성하도록 유도하기 위해"
    },
    {
        "subject": "[이론] PEFT",
        "question_text": "PEFT 기법 중, 모델의 가중치 행렬에 저차원(low-rank) 행렬을 추가하여 학습 파라미터 수를 줄이는 방식은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["Adapter Tuning", "Prefix Tuning", "Prompt Tuning", "LoRA"],
        "model_answer": "LoRA"
    },
    {
        "subject": "[이론] PEFT",
        "question_text": "LoRA에서, 학습된 어댑터 가중치의 영향력을 조절하는 스케일링 값으로 사용되는 하이퍼파라미터는 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["r (rank)", "lora_alpha", "lora_dropout", "bias"],
        "model_answer": "lora_alpha"
    },
    {
        "subject": "[이론] PEFT",
        "question_text": "모델의 가중치나 활성화 값을 더 적은 비트(bit)로 표현하여 모델 크기를 줄이고 추론 속도를 향상시키는 기술은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["양자화(Quantization)", "가지치기(Pruning)", "지식 증류(Knowledge Distillation)", "LoRA"],
        "model_answer": "양자화(Quantization)"
    },
    {
        "subject": "[이론] Foundation Model",
        "question_text": "LLM의 규모가 커짐에 따라 이전에 없던 새로운 능력이 나타나는 현상을 무엇이라고 합니까?",
        "question_type": "multiple_choice",
        "options": ["규모의 법칙(Scaling Law)", "창발적 능력(Emergent Abilities)", "인컨텍스트 학습(In-Context Learning)", "환각(Hallucination)"],
        "model_answer": "창발적 능력(Emergent Abilities)"
    },
    {
        "subject": "[이론] NLP",
        "question_text": "Word2Vec의 Skip-gram 모델이 CBOW에 비해 갖는 장점은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["학습 속도가 더 빠르다.", "더 큰 데이터셋에 적합하다.", "희귀 단어에 대한 임베딩 품질이 더 우수하다.", "메모리 사용량이 더 적다."],
        "model_answer": "희귀 단어에 대한 임베딩 품질이 더 우수하다."
    },
    {
        "subject": "[이론] Model Evaluation",
        "question_text": "데이터 불균형이 심한 분류 문제에서 다수 클래스를 모두 Negative로 예측해도 정확도(Accuracy)가 높게 나타나는 문제를 무엇이라고 합니까?",
        "question_type": "multiple_choice",
        "options": ["정확도의 역설(Accuracy Paradox)", "과적합(Overfitting)", "F1 스코어의 함정", "재현율의 한계"],
        "model_answer": "정확도의 역설(Accuracy Paradox)"
    },
    {
        "subject": "[이론] Deep Learning",
        "question_text": "과적합(Overfitting)을 완화하기 위한 데이터 증강(Data Augmentation) 기법이 아닌 것은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["이미지 회전 및 좌우 반전", "학습 데이터에 노이즈 추가", "훈련 데이터의 일부를 복제하여 양 늘리기", "생성 모델(GAN 등)을 사용하여 새로운 학습 데이터 생성"],
        "model_answer": "훈련 데이터의 일부를 복제하여 양 늘리기"
    },
    {
        "subject": "[이론] CV",
        "question_text": "CNN에서 스트라이드(Stride) 값을 1보다 크게 설정했을 때 얻는 효과는 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["특징 맵의 해상도를 높인다.", "특징 맵의 공간적 차원을 줄인다(Downsampling).", "모델의 파라미터 수를 늘린다.", "기울기 소실 문제를 악화시킨다."],
        "model_answer": "특징 맵의 공간적 차원을 줄인다(Downsampling)."
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM의 생성적 답변의 다양성을 조절하기 위해 사용되며, 값이 높을수록 더 무작위적인 샘플링을 유도하는 파라미터는 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["Temperature", "Top-p", "Top-k", "Beam width"],
        "model_answer": "Temperature"
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM의 디코딩 전략 중, 여러 개의 후보 시퀀스(beam)를 유지하며 가장 가능성 있는 문장을 탐색하는 방식은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["Greedy Decoding", "Beam Search", "Top-K Sampling", "Nucleus Sampling"],
        "model_answer": "Beam Search"
    },
    {
        "subject": "[이론] LLM",
        "question_text": "RLHF에서, 사람의 선호도 데이터를 학습하여 특정 응답이 얼마나 좋은지를 평가하는 모델은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["정책 모델(Policy Model)", "가치 모델(Value Model)", "보상 모델(Reward Model)", "환경 모델(Environment Model)"],
        "model_answer": "보상 모델(Reward Model)"
    },
    {
        "subject": "[이론] RAG",
        "question_text": "RAG 시스템에서 검색의 정확도를 높이기 위해, Bi-encoder로 후보군을 추리고 Cross-encoder로 재순위(re-ranking)를 매기는 방식을 무엇이라고 합니까?",
        "question_type": "multiple_choice",
        "options": ["단일 단계 검색(Single-stage Retrieval)", "2단계 검색(Two-stage Retrieval)", "희소 검색(Sparse Retrieval)", "조밀 검색(Dense Retrieval)"],
        "model_answer": "2단계 검색(Two-stage Retrieval)"
    },
    {
        "subject": "[이론] RAG",
        "question_text": "RAG에서 사용되는 Sparse Retriever와 Dense Retriever의 가장 큰 차이점은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["Sparse Retriever는 키워드 기반, Dense Retriever는 의미 기반으로 검색한다.", "Sparse Retriever는 벡터를 사용하고, Dense Retriever는 키워드를 사용한다.", "Sparse Retriever는 항상 더 빠르다.", "Dense Retriever는 색인 생성이 필요 없다."],
        "model_answer": "Sparse Retriever는 키워드 기반, Dense Retriever는 의미 기반으로 검색한다."
    },
    {
        "subject": "[이론] 머신러닝",
        "question_text": "PCA(주성분 분석)에 대한 설명으로 가장 올바른 것은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["데이터를 여러 군집으로 나누는 알고리즘이다.", "데이터의 분산을 최대한 보존하는 새로운 축(주성분)을 찾아 차원을 축소하는 기법이다.", "데이터의 클래스를 분류하는 지도 학습 알고리즘이다.", "결측치를 대체하는 데 사용되는 기법이다."],
        "model_answer": "데이터의 분산을 최대한 보존하는 새로운 축(주성분)을 찾아 차원을 축소하는 기법이다."
    },
    {
        "subject": "[이론] 데이터 전처리",
        "question_text": "데이터 스케일링 기법 중, 이상치(outlier)의 영향을 가장 많이 받는 것은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["표준화(Standardization)", "정규화(Min-Max Scaling)", "로버스트 스케일링(Robust Scaling)", "로그 변환(Log Transform)"],
        "model_answer": "정규화(Min-Max Scaling)"
    },
    {
        "subject": "[이론] NLP",
        "question_text": "트랜스포머 디코더에서, 현재 위치의 단어가 미래 위치의 단어 정보를 참고하지 못하도록 막는 장치는 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["패딩 마스크(Padding Mask)", "룩-어헤드 마스크(Look-Ahead Mask)", "세그먼트 마스크(Segment Mask)", "어텐션 스코어(Attention Score)"],
        "model_answer": "룩-어헤드 마스크(Look-Ahead Mask)"
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM이 사람의 가치나 의도에 부합하는 답변을 생성하도록 유도하는 전체적인 과정을 무엇이라고 합니까?",
        "question_type": "multiple_choice",
        "options": ["사전 학습(Pre-training)", "정렬(Alignment)", "양자화(Quantization)", "추론(Inference)"],
        "model_answer": "정렬(Alignment)"
    },
    {
        "subject": "[이론] PEFT",
        "question_text": "모델의 중요도가 낮은 가중치를 제거하여 모델을 경량화하는 Pruning 기법과 Quantization의 차이점은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["Pruning은 가중치를 제거하고, Quantization은 가중치의 정밀도를 낮춘다.", "Pruning은 가중치의 정밀도를 낮추고, Quantization은 가중치를 제거한다.", "두 기법은 동일한 목적을 가진 다른 이름이다.", "Pruning은 학습 중에만, Quantization은 추론 중에만 적용된다."],
        "model_answer": "Pruning은 가중치를 제거하고, Quantization은 가중치의 정밀도를 낮춘다."
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM을 평가하는 벤치마크 중, 초등학교 수준부터 전문가 수준까지 다양한 주제의 객관식 문제를 통해 모델의 지식과 추론 능력을 측정하는 것은 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["GLUE", "SuperGLUE", "MMLU", "SQuAD"],
        "model_answer": "MMLU"
    },
    {
        "subject": "[이론] RAG",
        "question_text": "LangChain에서 LLM, 프롬프트 템플릿, 출력 파서 등을 파이프(|) 기호로 연결하여 데이터 흐름을 만드는 방식을 무엇이라고 합니까?",
        "question_type": "multiple_choice",
        "options": ["LCEL (LangChain Expression Language)", "Agent Executor", "Callback Handler", "Toolchain"],
        "model_answer": "LCEL (LangChain Expression Language)"
    },
    {
        "subject": "[이론] 모델 평가",
        "question_text": "혼동 행렬(Confusion Matrix)에서 실제는 Negative인데 Positive로 잘못 예측한 경우를 무엇이라고 합니까?",
        "question_type": "multiple_choice",
        "options": ["True Positive (TP)", "True Negative (TN)", "False Positive (FP)", "False Negative (FN)"],
        "model_answer": "False Positive (FP)"
    },
    {
        "subject": "[이론] 모델 학습",
        "question_text": "딥러닝 모델이 학습을 반복함에 따라 훈련 데이터에 대한 손실은 계속 감소하지만, 검증 데이터에 대한 손실이 증가하기 시작하는 지점은 무엇을 시사합니까?",
        "question_type": "multiple_choice",
        "options": ["모델이 과소적합되고 있다.", "모델이 과적합되기 시작했다.", "학습률이 너무 낮다.", "최적의 모델에 도달했다."],
        "model_answer": "모델이 과적합되기 시작했다."
    },
    {
        "subject": "[이론] LLM",
        "question_text": "LLM이 안전 정책을 우회하여 유해하거나 부적절한 콘텐츠를 생성하도록 유도하는 프롬프팅 기법을 무엇이라고 합니까?",
        "question_type": "multiple_choice",
        "options": ["Chain-of-Thought", "Zero-shot Prompting", "Jailbreaking", "Instruction Tuning"],
        "model_answer": "Jailbreaking"
    },
    {
        "subject": "[이론] RAG",
        "question_text": "RAG 시스템에서 하이브리드 검색(Hybrid Search)이 필요한 이유는 무엇입니까?",
        "question_type": "multiple_choice",
        "options": ["키워드 기반 검색(Sparse)과 의미 기반 검색(Dense)의 장점을 결합하여 검색 성능을 높이기 위해", "검색 속도를 최대한 느리게 만들기 위해", "오직 키워드가 정확히 일치하는 문서만 찾기 위해", "검색 결과의 다양성을 줄이기 위해"],
        "model_answer": "키워드 기반 검색(Sparse)과 의미 기반 검색(Dense)의 장점을 결합하여 검색 성능을 높이기 위해"
    }
]