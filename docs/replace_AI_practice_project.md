# 실습 주관식 문제 중복 내역

이 문서는 새로 생성된 주관식 문제 (`AI_questions_practice_temp_sub.json`)가 기존 객관식 문제 (`AI_questions_practice.json`, `AI_questions_practice_temp.json`)와 개념적으로 겹치는 내역을 기록합니다. 문제 형식은 다르지만 동일한 핵심 개념을 다루고 있습니다.

---

- **New Short-Answer Question**:
  - `Scikit-learn의 train_test_split 함수에서 훈련/테스트 데이터 분할 시 클래스 비율을 유지하기 위해 사용되는 파라미터는 무엇인지 서술하시오.`
- **Overlaps with Multiple-Choice Question**:
  - `Scikit-learn의 train_test_split 함수에서 훈련/테스트 데이터 분할 시 클래스 비율을 유지하기 위해 사용되는 파라미터는 무엇입니까?`
- **Reason**: 두 문제 모두 `train_test_split` 함수의 `stratify` 파라미터에 대해 묻고 있습니다.

---

- **New Short-Answer Question**:
  - `PyTorch의 DataLoader의 역할은 무엇이며, shuffle 파라미터를 True로 설정하는 이유는 무엇인지 서술하시오.`
- **Overlaps with Multiple-Choice Question**:
  - `PyTorch의 DataLoader의 역할로 가장 올바른 설명은 무엇입니까?`
- **Reason**: 두 문제 모두 `DataLoader`의 핵심 역할(배치 처리, 셔플링)에 대해 묻고 있습니다.

---

- **New Short-Answer Question**:
  - `PyTorch에서 모델 학습 시, 매 배치마다 optimizer.zero_grad()를 호출하는 이유는 무엇인지 서술하시오.`
- **Overlaps with Multiple-Choice Question**:
  - `PyTorch에서 optimizer.zero_grad()를 호출하는 주된 이유는 무엇입니까?`
- **Reason**: 두 문제 모두 `optimizer.zero_grad()`의 목적(그래디언트 초기화)에 대해 묻고 있습니다.

---

- **New Short-Answer Question**:
  - `전이 학습(Transfer Learning)에서 '선형 프로빙(Linear Probing)'과 '미세 조정(Fine-tuning)'의 차이점을 학습되는 파라미터 범위 관점에서 서술하시오.`
- **Overlaps with Multiple-Choice Question**:
  - `전이 학습(Transfer Learning)의 한 방법인 '선형 프로빙(Linear Probing)'에 대한 가장 올바른 설명은 무엇입니까?`
- **Reason**: 두 문제 모두 전이 학습의 주요 방법론인 선형 프로빙과 미세 조정의 개념을 다루고 있습니다.

---

- **New Short-Answer Question**:
  - `RAG(Retrieval-Augmented Generation) 시스템에서 Retriever의 주요 역할은 무엇인지 서술하시오.`
- **Overlaps with Multiple-Choice Question**:
  - `RAG(Retrieval-Augmented Generation) 모델에서 Retriever의 주요 역할은 무엇입니까?`
- **Reason**: 두 문제 모두 RAG의 핵심 구성요소인 Retriever의 기능에 대해 묻고 있습니다.

---

- **New Short-Answer Question**:
  - `PEFT(Parameter-Efficient Fine-Tuning)의 주요 목표는 무엇인지 서술하시오.`
- **Overlaps with Multiple-Choice Question**:
  - `PEFT(Parameter-Efficient Fine-Tuning)의 주요 목표는 무엇입니까?`
- **Reason**: 두 문제 모두 PEFT의 근본적인 목적(효율적인 파인튜닝)에 대해 묻고 있습니다.
